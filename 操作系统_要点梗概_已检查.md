==操作系统导论==
20240131_吴主华_ 深圳技术大学 嵌入式软件开发

# 前言

常见操作系统：MacOS、IOS、Linux、Windows、NOKIA symbian

概念：操作系统，Operating System，是指控制和**管理**整个计算机系统的**硬件和软件**资源，并合理地组织调度计算机的工作和资源的分配；以提供给**用户和其他软件方便的接口和环境**；它是计算机系统中最基本的**系统软件**	
			*操作系统时系统资源的管理者、向上层提供方便易用的服务、最接近硬件的一层软件*

虚拟化CPU：在硬件的帮助下，操作系统负责实现将多任务并行的假象（illusion），即系统拥有了非常多CPU的假象。将单个CPU（或其中一小部分）转换为多个数量的CPU，从而让许多程序看似同时运行。在这里操作系统承担了资源管理器（resource manager）的角色

虚拟化内存（virtualizing memory）：每个进程访问自己的私有虚拟地址空间（virtual address space），操作系统以某种方式映射到机器的物理内存上。一个正在运行的程序中的内存引用不会影响其它进程的地址空间，对于正在运行的程序，它完全拥有自己的物理内存

并发：concurrency，指在同一时刻只能有一条指令执行，但多个进程指令被快速的轮换执行，使得在宏观上具有多个进程同时执行的效果，但在微观上并不是同时执行的，只是把时间分成若干段，使多个进程快速交替的执行。

持久性：persistence，在系统内存中需要硬件和软件来持久地（persistently）存储数据

操作系统实际上的工作：
			1 取得CPU、内存/磁盘等物理资源（resource），并对他们进行虚拟化
			2 处理与并发（concurrency）有关的麻烦问题
			3 持久性地（persistently）存储文件，从而使他们长期安全

# 第一章 操作系统概述

## 1.1 操作系统的概念、功能和目标

### 1.1.1 概念

操作系统（Operating System， OS）是指控制和管理整个计算机系统的硬件和软件资源，并合理地组织调度计算机的工作和资源的分配；以提供给用户和其他软件方便的接口和环境；它是计算机系统中最基本的系统软件

### 1.1.2 操作系统的功能和目标

#### （1） 作为系统资源的管理者

处理机管理、存储器管理、文件管理、设备管理（保证系统资源的安全与高效）

#### （2） 向上层提供方便易用的服务

- 命令接口（联机命令接口、脱机命令接口）：脱机命令接口=批处理命令接口、联机命令接口=交互式命令接口
- 程序接口：可以在程序中进行系统调用来使用程序接口。普通用户不能直接使用程序接口，只能通过程序代码间接使用
         系统调用类似于函数调用，是应用程序请求操作系统服务的唯一方式（系统调用 = 广义指令）
- GUI（图形用户界面 Graphical User Interface）：用户可以使用形象的图形界面进行操作，不需要记忆复杂的命令、参数

#### （3） 最接近硬件的层次

操作系统对硬件机器的拓展：将CPU、内存、磁盘、显示器、键盘等硬件合理地组织起来，让各种硬件能够相互协调配合，实现更多更复杂的功能，普通用户无需关心这些硬件在底层是怎么组织起来工作的，只需直接使用操作系统提供的接口即可

> 类比汽车：发动机——只会转；轮胎——只会滚；在原始的硬件机器上覆盖一层传动系统——让发动机带着轮子转——使原始的硬件机器得到拓展

## 1.2 操作系统的特征

### 1.2.1 并发和并行

概念：**并发**：指两个或多个事件在同一时间间隔内发生。这些事件宏观上是同时发生的，但微观上是交替发生的
	   	**并行**：指两个或多个事件在同一时刻同时发生

操作系统的并发性指计算机系统中“同时”运行着多个程序，这些程序宏观上看是同时运行着的，而微观 上看是交替运行的

- 单核CPU同一时刻只能执行一个程序，各个程序只能并发地执行 
- 多核CPU同一时刻可以同时执行多个程序，多个程序可以并行地执行

### 1.2.2 共享

概念：**资源共享**，是指系统中的资源可供内存中多个并发执行的进程共同使用

两种资源共享方式

- 互斥共享方式：一个时间段内只允许一个进程访问该资源
- 同时共享方式：允许一个时间段内由多个进程“同时”对它们进行访问

并发和共享的关系：

- 并发性指计算机系统中同时存在着多个运行着的程序
- 共享性是指系统中的资源可供内存中多个并发执行的进程共同使用

### 1.2.3 虚拟

概念：把一个物理上的实体变为若干个逻辑上的对应物。物理实体（前者）是实际存在的，而逻辑上对应物（后者）是用户感受到的

虚拟技术：空分复用计数、时分复用计数

### 1.2.4 异步

概念：在多道程序环境下，允许多个程序并发执行，但由于资源有限，进程的执行不是一贯到底的，而是走走停停的，以不可预知的速度向前推进。只有系统拥有并发性，才有可能导致异步性

## 1.3 操作系统的发展与分类

OS的发展与分类：手工操作阶段、纸带机（用户独占全机、人机速度矛盾）、批处理阶段（单道、多道批处理）、分时操作系统、实时操作系统、网络操作系统、分布式操作系统、个人计算机操作系统

- 分时操作系统：计算机以时间片为单位轮流为各个用户/作业服务，各个用户可通过终端与计算机进行交互
- 实时操作系统：能够优先响应一些紧急任务，某些紧急任务不需时间片排队，在实时操作系统的控制下，计算机系统接收到外部信号后及时进行处理，并且要在严格的时限内处理完事 件。实时操作系统的主要特点是及时性和可靠性
- 网络操作系统：是伴随着计算机网络的发展而诞生的，能把网络中各个计算机有机地结合起来，实现数据传 送等功能，实现网络中各种资源的共享（如文件共享）和各台计算机之间的通信
- 分布式操作系统：主要特点是分布性和并行性。系统中的各台计算机地位相同，任何工作都可以分布在这些 计算机上，由它们并行、协同完成这个任务

## 1.4 操作系统的体系结构

- 大内核将操作系统的主要功能模块都作为系统内核，运行在核心态；高性能，但内核代码庞大，结构混乱，难以维护
- 微内核：只把最基本的功能保留在内核；内核功能少，结构清晰，但需要频繁的在核心态和用户态之间切换

操作系统内核主要实现的功能：

- 时钟管理：实现计时功能
- 中断处理：负责中断机制
- 原语：一种特殊的程序，处于操作系统最底层，程序运行具有原子性，不可中断，运行时间短，调用频繁
- 对系统资源进行管理的功能：进程管理、存储器管理、设备管理

## 1.5 中断和异常

中断：Interruption，也称外中断，指来自CPU执行指令以外的事件的发生，“中断”是让操作系统内核夺回CPU使用权的唯一途径

中断的分类

- 外中断：中断，与当前执行的指令无关，中断信号来源自CPU外部
- 内中断：也称**异常**（Exception），与当前执行的指令有关，中断信号来源于CPU内部

中断机制的基本原理：不同的中断信号，需要用不同的中断处理程序来处理。当CPU检测到中断信号后，会根据中断信号 的类型去查询“中断向量表”，以此来找到相应的中断处理程序在内存中的存放位置

## 1.6 系统调用

**概念**：操作系统提供给应用程序（程序员/编程人员）使用的接口，可以理解为一种可供应用 程序调用的特殊函数，应用程序可以通过系统调用来请求获得操作系统内核的服务

系统调用和库函数的**区别**：

- 系统调用是操作系统向上层提供的接口
- 有的库函数是对系统调用的进一步封装
- 当今编写的应用程序大多是通过高级语言提供的库函数间接地进行系统调用

系统调用的**作用**：应用程序通过系统调用请求操作系统的服务。而系统中的各种共享资源都由操作系统内核统一掌管，因此凡是 与共享资源有关的操作（如存储分配、I/O操作、文件管理等），都必须通过系统调用的方式向操作系统内核提 出服务请求，由操作系统内核代为完成。这样可以保证系统的稳定性和安全性，防止用户进行非法操作

系统调用**分类**（按功能分）：

- 设备管理：完成设备的请求/释放/启动等功能
- 文件管理：完成文件的读/写/创建/删除等功能
- 进程控制：完成进程的创建/撤销/阻塞/唤醒等功能
- 内存管理：完成内存的分配/回收等功能

系统调用的过程：传递系统调用参数 -> 执行陷入指令（用户态）-> 执行相应的内请求核程序处理系统调用（核心态）-> 返回应用程序
		陷入指令是在用户态执行的，执行陷入指令之后立即引发一个内中断，使CPU进入核心态
		发出系统调用请求是在用户态，而对系统调用的相应处理在核心态下进行

# 第二章 进程管理

## 2.1 进程与线程

### 2.1.1 进程的概念、组成和特征

#### （1）进程的概念

进程（Process）：是进程实体的运行过程，是系统进行资源分配和调度的一个独立单元
       进程实体：即进程映像，是静态的。 进程实体反应了进程在某一时刻的状态）
		进程：是动态的，是程序的一次执行过程
		程序：是静态的，就是个存放在磁盘里的 可执行文件，就是一系列的指令集合（同一个程序多次执行会对应多个进程）

当进程被创建时，操作系统会为该进程 分配一个唯一的、不重复的“身份证 号”—— PID（Process ID，进程ID）

#### （2） 进程的组成

PCB是给操作系统用的。 程序段、数据段是给进程自己用的

1. 进程控制块PCB

Process Control Block，进程存在唯一的标志，当进程被创建时，操作系统为其 创建PCB，当进程结束时，会回收其PCB
操作系统对进程进行**管理工作**所需的信息都存在PCB中

- 进程描述信息：进程标识符PID、用户标识符UID
- 进程控制和管理信息：CPU、磁盘、网络流量使用情况统计······、进程当前状态（就绪态/阻塞态/运行态······）
- 资源分配清单：正在使用的哪些文件、内存区域、I/O设备
- 处理机相关信息：如PSW、PC等等各种寄存器的值（用于实现进程切换）

2. 程序段：程序的代码（指令序列）

3. 数据段：运行过程中产生的各种数据（如程序中定义的变量）

#### （3） 进程的特征

- 动态性：进程是程序的一次执行过程，动态地产生、变化和消亡
- 并发性：内存中有多个进程实体，各进程可并发执行
- 独立性：独立运行、独立获得资源、独立接受调度的基本单元
- 异步性：进程间相互制约，具有执行的间断性，各进程各自独立，以不可预知的速度向前推进
- 结构性：每个进程都配置一个PCB

#### （4） 进程的组织

在一个系统中，通常有数十、数百乃至数千个PCB。为了能对他们加以有效的管理，应该用适当的方式把这些PCB组织起来。 
注：**进程的组成**讨论的是一个进程内部由哪些部分构成的问题，而**进程的组织**讨论的是多个进程之间的组织方式问题

- 链接方式：按照进程状态将PCB分为多个队列、操作系统持有指向各个队列的指针
- 索引方式：根据进程状态的不同，建立几张索引表、操作系统持有指向各个索引表的指针
  <img src="C:/Users/Small Black/AppData/Roaming/Typora/typora-user-images/image-20240221103609179.png" alt="image-20240221103609179" style="zoom:50%;" />
  <img src="C:/Users/Small Black/AppData/Roaming/Typora/typora-user-images/image-20240221103632087.png" alt="image-20240221103632087" style="zoom:50%;" />

### 2.1.2 进程的状态与转换

- 运行状态：占有CPU，并在CPU上运行，单核只能一个进程（双核两个）

- 就绪状态：已经具备运行条件，但是没有空闲的CPU，暂时不能运行

- 阻塞状态：等在某个事件的发生，暂时不能运行

- 创建状态：创建PCB，程序段，数据段

- 终止状态：回收内存，程序段，数据段，撤销PCB


**进程状态间的转换**
<img src="C:/Users/Small Black/AppData/Roaming/Typora/typora-user-images/image-20240221104128173.png" alt="image-20240221104128173" style="zoom:50%;" />

### 2.1.3 进程控制

#### (1) 基本概念

进程控制的主要功能是对系统中的所有进程实施有效的管理，它具有创建新进程、撤销已有进程、实现 进程状态转换等功能
	**实质**就是实现各种进程状态转换

进程控制的实现方式：**原语**
	原语是一种特殊的程序， 它的执行具有原子性。 也就是说，这段程序的 运行必须一气呵成，不可中断
	可以用 “关中断指令”和“开中断指令”这两个特权指令实现**原子性**（关中断后不再例行检查中断信号）

原语做的事情：更新PCD中的信息、将PCD插入合适的队列、分配/回收资源

#### (2) 进程控制相关的原语

1.进程的创建

- 创建原语：申请空白PCB、为新进程分配所需资源、初始化PCB、将PCB插入就绪队列

- 引起进程创建的事件：用户登录、作业调度、提供服务、应用请求


2.进程的终止

- 撤销原语：将就绪态/阻塞态/运行态的进程切换为终止态，回收资源，删除PCB

- 引起进程中止的事件：正常结束（进程自主终止）、异常结束（非法使用特权指令/整数除于0等）、外界干预（用户杀掉进程）


3.进程的阻塞

- 阻塞原语：运行态->阻塞态

- 引起进程阻塞的事件：需要等待系统分配某种资源、需要等待相互合作的其他进程完成工作


4.进程的唤醒

- 唤醒原语：阻塞态->就绪态

- 引起进程唤醒的事件：等待的事件发生


5.进程的切换

- 切换原语：运行环境存入PCB（进程上下文） -> PCB移入相应队列 -> 选择另一个进程执行并更新PCB

- 引起进程切换的事件：当前进程事间片到、有更高优先级的进程到达、当前进程主动阻塞、当前进程终止

进程原语**主要工作**总结

- 更新PCB中的信息 
  		a. 所有的进程控制原语一定都会修改进程状态标志 
       b. 剥夺当前运行进程的CPU使用权必然需要保存其运行环境 
       c. 某进程开始运行前必然要恢复期运行环境 
- 将PCB插入合适的队列以及分配/回收资源

### 2.1.4 进程通信

进程通信就是指进程之间的信息交换。 进程是分配系统资源的单位（包括内存地址空间），因此各进程拥有的内存地址空间相互独立
为了保证安全，一个进程不能直接访问另一个进程的地址空间。 但进程之间的信息交换必须实现依靠某种方法实现

#### （1） 共享存储

 在通信的进程之间存在一块可直接访问的共享空间，通过对这片共享空间进行写/读操作实现进程间通信
 操作系统只负责提供共享空间和同步互斥工具（如P、V操作），同时两个进程对共享空间的访问必须是互斥的

常见的两种共享方式：基于数据结构的共享：固定分配（低级）；基于存储区的共享：划分存储区（高级）

#### （2） 消息传递

进程间的数据交换以格式化的消息（Message）为单位。进程通过操作系统提供的“发送消息/接收 消息”两个原语进行数据交换

格式化消息：包括消息头和消息体
		消息头：发送进程ID、接 受进程ID、消息类型、消息长度等格式化的信息（计算机网络中的“报文”其实就是一种格式化的消息）
		消息体：具体的信息数据

- 直接通信方式：消息直接挂到接收进 程的消息缓冲队列上

- 间接通信方式：消息要先发送到中间实体（信箱）中，因此 也称“信箱通信方式”，即间接地进行


#### （3） 管道通信（pipe）

“管道”是指用于连接读写进 程的一个共享文件，又名pipe 文件。其实就是在内存中开辟 一个大小固定的缓冲区

特点：

- 半双工通信且各进程要互斥地访问管道
- 数据以**字符流**的形式写入管道，当管道写满时，写进程的write()系统调用将被阻塞，等待读进程将数据 取走。当读进程将数据全部取走后，管道变空，此时读进程的read()系统调用将被阻塞，如果没写满，就不允许读。如果没读空，就不允许写
- 数据一旦被读出，就从管道中被抛弃，这就意味着读进程最多只能有一个，否则可能会有读错数据的情况


### 2.1.5  线程概念和多线程模型

#### （1） 线程的概念和特点

线程：CPU调度的基本单位
		进程：资源分配的基本单位，从属于同一进程的各个线程共享进程的资源

1.线程的特点

- 线程是CPU调度的单位，进程是资源分配的单位
- 同一进程的各线程共享进程拥有的资源
- 同一进程内的线程切换不会导致进程切换

2.引入线程带来的变化

- 资源分配、调度上的变化：引入线程后线程是CPU调度的基本单位单位，进程是资源分配的基本单位
- 并发性：引入线程机制后，各线程间也可并发，系统并发性提高
- 系统开销：同一进程内的线程切换不会需要切换进程环境，系统开销小

3.线程的实现方式

用户级线程（User-Level Thread, ULT）：应用程序通过线程库实现，所有的线程管理工作都由应用程序负责（包括线程切换） 用户级线程中，线程切换可以在用户态下完成，无需操作系统干预。 

内核级线程（Kernel-Level Thread, KLT, 又称“内核支持的线程”）：内核级线程的管理工作由操作系统内核完成。 线程调度、切换等工作都由内核负责，因此内核级线程的切换必然需要在核心态下才能完成
		可以理解为，“内核级线程”就是“从操作系统内核视角看能看到的线程” 

*操作系统只“看得见”内核级线程，因此只有内核级线程才是处理机分配的单位*

> 部分系统采用组合方式的多线程实现

4.多线程模型

在同时支持用户级线程和内核级线程的系统中，由几个用户级线程映射到几个内核级线程的问题引 出了“多线程模型”问题

- 多对一模型：多个用户及线程映射到一个内 核级线程。每个用户进程只对应一个内核级线程
  	优点：用户级线程的切换在用户空间即可完 成，不需要切换到核心态，线程管理的系统 开销小，效率高
  	缺点：当一个用户级线程被阻塞后，整个进 程都会被阻塞，并发度不高。多个线程不可 在多核处理机上并行运行
- 一对一模型：一个用户及线程映射到一个内 核级线程。每个用户进程有与用户级线程同 数量的内核级线程
  	优点：当一个线程被阻塞后，别的线程还可以继续执行，并发能力强。多线程可在多核 处理机上并行执行
  	缺点：一个用户进程会占用多个内核级线程， 线程切换由操作系统内核完成，需要切换到 核心态，因此线程管理成本高，开销大
- 多对多模型：n 用户及线程映射到 m 个内核 级线程（n >= m）。每个用户进程对应 m 个 内核级线程
  	克服了多对一模型并发度不高的缺点，又克服了一对一模型中一个用户进程占用太多内核级线程，开销太大的缺点

## 2.2 处理机调度

### 2.2.1调度概念、层次

处理机调度：从就绪队列中按照一定的算法选择一个进程并将处理机分配给它运行，以实现进程的**并发执行**

**三个层次**

1. 高级调度（**作业调度**）  外存 ----> 内存（面向作业）

- 按一定的原则从外存上处于后备队列的作业中挑选一个（或多个）作业， 给他们分配内存等必要资源，并建立相应的进程（建立PCB），以使它（们）获得竞争处理机的权利
- 高级调度是辅助外存与内存之间的调度，作业调入时会建立相应的PCB，作业调出时才撤销PCB，调入可由操作系统决定，调出由作业运行结束才调出

2. 中级调度（**内存调度**）外存 ----> 内存（面向进程）

- 决定将哪个处于挂起状态的进程重新调入内存
- 一个进程可能会被多次调出、调入内存，因此中级调度发生的频率要比高级调度更高


3. 低级调度（**进程调度**） 内存 ----> cpu

- 主要任务是按照某种方法和策略从就绪队列中选取一个进程，将处理 机分配给它。 
- 进程调度是操作系统中最基本的一种调度，在一般的操作系统中都必须配置进程调度。 进程调度的频率很高，一般几十毫秒一次

### 2.2.2 进程调度的时机、切换与过程、调度方式

#### （1） 时机

什么时候需要进程调度？

- 运行中的进程主动放弃：进程正常终止、运行过程中发生异常而终止、进程主动请求阻塞
- 运行中的进程被动放弃：分给进程的时间片用完、有更紧急的事需要处理、有更高优先级的进程进入就绪队列

什么时候不能进行进程调度？

- 在处理中断的过程中
- 进程在操作系统内核程序临界区中
  内核程序临界区一般是用来访问某种内核数据结构的，比如进程的就绪队列（由各就绪进程的PCB组成）
  临界资源：一个时间段内只允许一个进程使用的资源。各进程需要互斥地访问临界资源（临界区：访问临界资源的那段代码）
- 在原子操作过程中（原语），原子操作不可中断，要一气呵成（如 之前讲过的修改PCB中进程状态标志，并把PCB放到相应队列）

#### （2） 切换与过程

**狭义的进程调度**：从就绪队列中选中一个要运行的进程。（这个进程可以是刚刚被暂停执行的进程， 也可能是另一个进程，后一种情况就需要进程切换） 
**进程切换**：一个进程让出处理机，由另一个进程占用处理机的过程（广义的进程调度包含了选择一个进程和进程切换两个步骤）

进程切换的过程

- 对原来运行进程各种数据的保存
- 对新的进程各种数据的恢复（如：程序计数器、程序状态字、各种数据寄存器等处理机现场信息，这些信息一般保存在进程控制块）

#### （3） 调度方式

非剥夺调度方式（非抢占式）：只允许进程主动放弃处理机。在运行过程中即便有更紧迫 的任务到达，当前进程依然会继续使用处理机，直到该进程终止或主动要求进入阻塞态

剥夺调度方式（抢占式）：当一个进程正在处理机上执行时，如果有一个更重要或更紧迫的进 程需要使用处理机，则立即暂停正在执行的进程，将处理机分配给更重要紧迫的那个进程

### 2.2.3 调度算法的评价指标

- CPU利用率：CPU利用率 = CPU忙碌的时间 / 总时间，指CPU “忙碌”的时间占总时间的比例

- 系统吞吐量：系统吞吐量 = 总共完成了多少道作业 / 总共画了多少时间，即单位时间内完成作业的数量

- 周转时间：周转时间 = 作业完成时间 – 作业提交时间，指从作业被提交给系统开始，到作业完成为止的这段时间间隔
  	包括四个部分：作业在外存后备队列上等待作业调度（高级调度）的时间、进程在就绪队列上等待进程调度（低级调度）的时间、进程在CPU上执行的时间、进程等待I/O操作完成的时间。后三项在一个作业的整个处理过程中，可能发生多次。
- 等待时间：进程/作业处于等待处理机状态时间之和
  		进程：等待时间是指进程建立后等待被服务的时间之和，在等待I/O完成的期间其实进 程也是在被服务的，所以不计入等待时间
    		作业：不仅要考虑建立进程后的等待时间，还要加上作业在外存后备队列中等待的时间
- 响应时间：从用户提交请求到首次产生响应所用的时间

### 2.2.4 FCFS、SJF、HRRN调度算法

这几种算法主要关心对用户的公平性、平均周转时间、平均等待时间等评价系统整体性能的指标，但不关心“响应时间”，也并不区分任务的紧急程度，因此对于用户来说，交互性差。因此这三种算法一般适合用于早期的批处理系统

#### (1) 先来先服务（FCFS）

- 先到达先进行服务，按照作业/进程到达的先后顺序进行服务

- 非抢占式、公平、算法实现简单

- 对长作业有利、对短作业不利，排在长作业/进程后面的短作业需要等待很长时间，带权周转时间很大，对短作业来说用户体验不好


#### (2) 短作业优先（SJF，shortest job first）

- 最短（要求服务时间最短）的作业优先得到服务，时间相同，先到达的先被服务
- 每次调度时选择当前已到达且运行时间最短的作业/进程
- 在所有进程都几乎同时到达时，采用SJP调度算法的平均等待时间、平均周转时间最少

- 抢占式版本：最短剩余时间优先算法（SRTN）每当有进程加入就绪队列改变时就需要调度，如果新到达的进程剩余时间比当前运行的进程剩余时间更短，则由新进程抢占处理机，当前运行进程重新回到就绪队列。另外，当一个进程完成时也需要调度

#### (3) 高响应比优先（HRRN）

- 非抢占式的调度算法，只有当前运行的进程主动放弃CPU时（正常/异常完成，或主动阻塞），才进行调度，调度时计算所有就绪进程的响应比，选响应比最高的进程上处理机
- 响应比=（等待时间+要求服务时间）/ 要求服务时间
- 要综合考虑作业/进程的等待时间和要求服务的时间，等待时间相同时，要求服务时间短的优先（SJF 的优点） 要求服务时间相同时，等待时间长的优先（FCFS 的优点） 对于长作业来说，随着等待时间越来越久，其响应比也会 越来越大，从而避免了长作业饥饿的问题


### 2.2.5 时间片轮转、优先级调度、多级反馈队列（适合交互式系统）

#### (1） 时间片轮转算法（RR）

算法思想：公平轮流地位各个进程服务，让每个进程在一定时间间隔内都可以得到响应

算法规则：按照各进程到达就绪队列的顺序，轮流让各个进程执行一个时间片（如100 ms）。若进程未在一个时间片内执行完，则剥夺处理机，将进程重新放到就绪队列对位重新排队

抢占式、响应快，适用于分时操作系统，但由于高频率的进程切换，因此有一定的开销且不区分任务的紧急程度

#### （2） 多级反馈队列调度算法

- 算法实现：设置多级就绪队列，各级队列优先级从高到低，时间片从小到大。新进程到达时先进入第一级队列，按照FCFS原则排队等待被分配时间片。若用完时间片进程还未结束，则进程进入下一级队列对位。如果此时已经在最下级的队列，则重新放回最下级队列末尾。当只有第K级队头的进程为空时，才会为K+1级对头的进程分配时间片，被抢占处理机的进程重新放回原队列队尾。

- 优点：对各个进程相对公平（FCFS的优点），每个新到达的进程都可以很快就得到响应（RR的优点）；短进程只用较少的时间就可以完成（SPF的优点）；不必实现估计进程的运行时间（避免用户作假）；可灵活地调整对各类进程的偏好程度，比如CPU密集型进程、IO密集型进程

## 2.3 进程同步

### 2.3.1 进程同步与互斥

#### （1） 进程同步

也叫直接制约关系，指为了完成某种任务而建立的两个或多个进程，这些进程因为需要在某些位置上协调工作次序而产生的制约关系

#### （2） 进程互斥

也称间接制约关系，当一个进程进入临界区使用临界资源时，另一个进程必须等待，当占用临界资源的进程退出临界区后，另一进程才允许区访问此临界资源

临界资源：把一个时间段内只允许一个进程使用的资源称为

对临界资源的互斥访问，可以在逻辑上分为四个部分：

```C
do{
  entry section;   	 //进入区  对访问的资源检查或进行上锁
  critical section;  //临界区(段) 访问临界资源的那部分代码
  exit section;      //退出区  负责解锁
  remainder section; //剩余区  其它处理
} while(true)C
```

禁止两个进程同时进入临界区，同步机制应遵循的准则

- 空闲让进，临界区空闲时，可以允许一个请求进入临界区的进程立即进入临界区
- 忙则等待，当已有进程进入临界区时，其他进程等待
- 有限等待，当请求访问的进程，应保证能在有限的时间进入临界区
- 让权等待，当进程不能进入临界区时，应立即释放处理器，防止进程忙等待

#### (3) 进程互斥的软件实现

在进入区设置并检查标志来表明是否有进程在临界区中，若已有进程在临界区，则在进入区通过循环检查进行等待，进程离开临界区后则在退出区修改标志

1. 单标志法

两个进程在访问完临界区后会把使用临界区的权限教给另一个进程。也就是说每个进程进入临界区的权限只能被另一个进程赋予

```C
int turn =0;		//标志位，p1要访问的话，必须p0先访问，违背：空闲让进原则C
//p0进程
while(turn!=0);		 //进入区
critical section;	 //临界区
turn = 1;			//退出区置标志位
remainder section;	 //剩余区
//p1进程
while(turn!=1);
critical section;
turn = 0;
remainder section;
/*该算法需要两个进程交替进入临界区，若某个进程不再进入临界区，则另一个进程也无法进入临界区 ----> 违背“空闲让进”原则*/
```

2. 双标志先检查 

算法思想:设置一个bool数组flag[]来标记自己是否想要进入临界区的意愿

```C
bool flag[2]={false,false};
//p1进程
while(flag[1]);		//进入区
flag[0]=true;		//进入区
critical section;	//临界区
flag[0]=false;		//退出区
remainder section;	//剩余区
//p2进程
while(flag[0]);
flag[0]=true;
critical section;C
flag[1]=false;
remainder section;
/*该算法两个进程可能同时进入临界区，即在检查对方的flag后切换自己的flag前有一段空闲时间 ----> 违背“忙则等待”原则*/
```

3. 双标志后检查

算法思想:设置一个bool数组flag[]来标记自己是否想要进入临界区的意愿，但会先将自己的标志设置为`TRUE`，再检查对方标志而进行操作

```C
bool flag[2]={false,false};
//p1进程
flag[0]=true;
while(flag[1]);
critical section;
flag[0]=false;
remainder section;
//p2进程
flag[0]=true;
while(flag[0]);
critical section;C
flag[1]=false;
remainder section;
/*由于进程是并发进行的，可能会两个同时上锁，都进不去，违反空闲让进和有限等待原则*/
```

4. Peterson 算法

设置变量turn，防止两个进程为进入临界区而无限等待，每个进程先设置自己的标志后再设置turn标志。这时，再同时检查另外一个进程状态标志和不允许进入标志，以便保证两个进程同时要求进入临界区时，只允许一个进程进入临界区

```C
bool flag[2]={false,false};
int turn=0;
//p1进程
flag[0]=true;			//进入区
turn=1;				    //进入区
while(flag[1]&&turn==1); //进入区
critical section;		//临界区
flag[0]=false;			//退出区
remainder section;		//剩余区
//p2进程
flag[1]=true;
turn=0;
while(flag[0]&&turn==0);
critical section;C
flag[1]=false;
remainder section;
```

#### （4） 进程互斥的硬件实现方法

1. 中断屏蔽方法

- 利用“开/关中断指令”实现（与原语的实现思想相同，即在某进程开始访问临界区到结束访问为 止都不允许被中断，也就不能发生进程切换，因此也不可能发生两个同时访问临界区的情况）
- 不适用于多处理机；只适用于操作系统内核进程，不适用于用户进程（因为开/关中断指令 只能运行在内核态，这组指令如果能让用户随意使用会很危险）

2. TestAndSet（TSL指令）

TSL是用硬件实现的，执行的过程不允许被中断
		不满足“让权等待”原则，暂时无法进入临界区的进程会占用CPU并循环执行TSL指令，从 而导致“忙等

C语言描述逻辑：

```C
//true表示已经上锁 false表示未加锁
bool TestAndSet(bool *lock){
  bool old;		//布尔型共享变量，表示当前临界区是否被加锁
  old=*lock;	//存放lock原来的值
  *lock=true;	//无论之前是否已加锁，都将lock设为true
  return old;	//返回lock原来的值
}
//以下是使用TSL指令实现互斥的算法逻辑
while(TestAndSet (&lock));//上锁并检查
临界区代码段
lock=false; //解锁
```

3. Swap指令

别称：Exchange指令、XCHG指令，硬件实现的，执行的过程不允许被中断
C语言逻辑如下：

```C
//true表示已经上锁 false表示未上锁
void Swap(bool *a,bool *b){		//Swap指令的作用时交换两个变量的值
  bool temp;
  temp=*a;
  *a=*b;
  *b=temp;
}
//以下是使用Swap指令实现互斥的算法逻辑 lock表示当前临界区是否被加锁
bool old=true;
while(old=true)
  Swap(&lock,&old);
/*临界区代码段C*/
lock=false; //解锁
/*剩余代码段*/
```

### 2.3.2 信号量机制

信号量：本质为一个变量 ，可用一个信号量来表示系统中某种资源的数量，比如：系统中一台打印机，就可以设置一个初值为1的信号量

一对原语：wait（S）原语和signal（S）原语，分别简称P（S）、V（S）操作，可以把原语理解为我们自己写的函数，函数名分别为 wait 和 signal，括号里的信号量 S 其实就是函数调用时传入的一个参数

#### （1） 整形信号量

用一个整数表示系统资源的变量，用来表示系统中某种资源的数量（对信号量只能执行初始化、P、V三种操作）
C程序示例：

```C
int S=1;			//初始化整型信号量S
void wait(int S){ 	 //wait原语，相当于：进入区
  while(S<=0); 		 //如果资源数不够，就意志循环等待
  S=S-1;    		 //如果资源数够，则占用一个资源
}

void signal(int S){	  //signal原语，相当于“退出区”
  S=S+1;    		 //使用完资源后，在退出区释放资源
}					/*进程间可能会出现盲等*/
```

#### （2） 记录型信号量

用记录型数据结构表示的信号量（可实现系统资源的“申请”和“释放”、可实现进程互斥、进程同步）

```C
typedef struct{			//记录型信号量的数据结构定义
  int value;			//剩余资源值
  struct process *L;	 //等待该资源的队列
} semaphore;
void wait (semaphore S){ //某进程需要使用资源时，通过wait原语申请 -----> P操作
  S.value--;			//资源数减1，对信号量S的一次P操作意味着进程请求一个单位的该类资源，资源减少
  if(S.value<0){		//S.value<0时表示该类资源已分配完毕，因此进程应调用block原语进行自我阻塞（当前运行的进程从运行态
  block (S.L);           //->阻塞态）并插入该类资源的消息等待队列S.L中。机制遵循了“让权等待”原则，不会出现“忙等”现象
 }
}
void signal (semaphore S){//进程使用完资源后，通过signal原语释放  ------> V操作
  S.value++;			 //进程释放一个单位的资源，资源数加1
  if(S.valie<=0){         //若加1后仍是 S.value <= 0，表示依然有进程在等待该类资源，因此应调用 wakeup 原语唤醒等待
    wakeup(S.L);          //队列中的第一个进程（被唤醒进程从阻塞态->就绪态）	
 }
}
```

#### （3） 用信号量机制实现进程互斥、同步、前驱关系

1、信号量机制实现进程互斥，示例伪代码

```C
typedef struct{			//记录型信号量的数据结构定义
  int value;			//剩余资源值
  struct process *L;	 //等待该资源的队列
} semaphore;
semaphore mutex = 1;	 //初始化信号量
p1(){					//进程1
    /******/
    P(mutex);			 //使用临界资源前加锁 进入区
    /***临界区段代码**/
    V(mutex)			 //使用临界资源后解锁 退出区
    /*********/
}
p2(){					//进程2
    /******/
    P(mutex);			 //使用临界资源前加锁 进入区
    /***临界区段代码**/
    V(mutex)			 //使用临界资源后解锁 退出区
    /*********/
}/*P、V操作必须成对出现，缺少P(mutex)就不能保证临界资源的互斥访问。缺少V(mutex) 会导致资源永不被释放，等待进程永不被唤醒*/
```

2、实现进程同步

要让各并发进程按要求有序地推进，即让本来**异步并发的进程**互相配合，有序推进（在“前操作”之后执行V(S)在“后操作”之后执行P(S)）

```C
semaphore S = 0;		//初始化同步信号量，初始值为0
p1(){					//进程1
    /***代码1***/
    /***代码2***/
    V(S)			 	//释放资源
    /***代码3***/
}
p2(){//进程2		    //若先执行到V(S)操作，则S++后S=1。之后当执行到P(S)操作时，由于S=1，表示有可用资源，会执行S--，
    P(S);			 //S的值变回0，P2 进程不会执行 block 原语，而是继续往下执行代码4
    /***代码1***/		//若先执行到P(S)操作，由于S=0，S--后S=-1，表示此时无可用资源，因此P操作中会执行block原语，主动请求
    /***代码2***/		//阻塞。之后当执行完代码2，继而执行V(S)操作，S++，使S变回0，由于此时有进程在该信号量对应的阻塞队列	
    /***代码3***/	    //中，因此会在V操作中执行wakeup原语，唤醒P2进程。这样P2就可以继续执行代码4了
}
```

3、实现进程的前驱关系

- 实际上每一对前驱关系都是一个进程同步问题（需要保证一前一后的操作）
- 要为每一对前驱关系各设置一个同步变量、在“前操作”后对相应的同步变量执行V操作、在“后操作”前对相应的同步变量执行P操作

### 2.3.3 管程

能不能设计一种机制，让程序员写程序时不需要再关注复杂的PV操作，让写代码更轻松?
		*管程的实质是一种进程同步机制

#### （1）管程的定义和基本特征

定义：代表共享资源的数据结构，统一管理对共享资源的所有访问，实现进程互斥，这个代表共享资源的数据结构，以及由对该共享数据结构实施操作的一组过程所组成的资源管理程序，称为管程

管程的四个组成部分：

- 局部于管程内部的共享数据结构说明
- 对该数据结构进程操作的一组过程（或函数）
- 对局部于管程的共享数据设置初始值的语句
- 管程的名字

基本特征：（相当于C++的类，管程是数据放在private中，函数放在public中）

- 管程内的共享数据结构只能被管程内的过程所访问
- 一个进程只有通过调用管程内的过程才能进入管程访问共享数据
- 每次仅允许一个进程在管程内执行某个内部过程（进程互斥）

#### （2） 条件变量

定义：进程阻塞进入管程的原因。当一个进程进入管程后被阻塞，直到阻塞的原因解除时，在此期间，如果该进程不释放管程，那么其他进程无法进入管程。

一个进程被阻塞的原因由多个，因此在管程中可以设置多个条件变量。每个条件变量保存了一个等待队列，用于记录因该条件变量而阻塞的所有过程，**对条件变量只能进行两种操作，wait和signal**

```C
//示例伪代码
monitor Demo{
    struct S;	//共享数据结构
    condition x;//定义一个条件变量
    init_code(){/******/}
    take_away(){
        if(S <= 0) x.wait();	//资源不够，在条件变量x上阻塞等待
        else{
            /**/		//资源足够，分配资源，进一步逻辑操作
        }
    }
    give_back(){
        //归还资源，做一系列处理
        if(/*有进程等待*/) x.signal;	//唤醒一个阻塞进程
    }
}
```

#### （3） 信号量和条件变量的比较

相似点：条件变量的wait/signal操作类似于信号量的P/V操作，可以实现进程的阻塞/唤醒
不同点：条件变量是“没有值的”，**仅实现“排队等待”功能**；而信号量是“有值”的，信号量的值反映了剩余资源数，而在管程中，剩余资源用共享数据结构记录

拓展1：用管程解决生产者消费者问题

```C
monitor producerconsumer
  condition full,empty;
  int count = 0;
  void insert(Item item){
    if(count == N)
      wait(full);
    count++;
    insert_item (item);
    if(count == 1)
      signal(empty);
 }
  Item remove(){
    if(count == 0)
      wait(empty);
    count--;
    if(count == N-1)
      signal(full);
    return remove_item();
 }
  end monitor;

//使用
producer(){
  while(1){
    item = 生产一个产品;
    producerconsumer.insert(item);
 }
}

consumer(){
  while(1){
    item = producerconsumer.remove();C
    消费产品 item;
 }
}
```

拓展2： Java中类似于管程的机制

java中用synchronized来描述一个函数,这个函数同一时间只能被一个线程调用

### 2.3.4 经典同步问题例子

#### （1） 生产者-消费者问题

- 只有缓冲区没满时，生产者才能把产品放入缓冲区，否则必须等待

- 只有缓冲区不空时，消费者才能从中取出产品，否则必须等待

- 缓冲区是临界资源，各个进程互斥访问

- 实现互斥的P操作要放在实现同步的P操作之后，不然会发生死锁

- V操作不会导致进程发生阻塞的状态，所以可以交换

- 使用操作不要放在临界区，不然并发度会降低


#### （2） 多生产者-多消费者模型

- 在生产-消费者问题中，如果缓冲区大小为1，那么有可能不需要设置互斥信号量就可以实现互斥访问缓冲区

- 分析同步问题是，应该从“事件”的角度来考虑


#### （3） 2.3.8 吸烟者问题

- 解决“可以让生产多个产品的单生产者”问题提供一个思路；

- 若一个生产者要生产多种产品（或者说会引发多种前驱事件），那么各个V操作应该放在各自对应的“事件”发生之后的位置


#### （4） 读者-写者问题

- 允许多个读者同时对文件执行读操作
- 只允许一个写者往文件中写信息

- 任一写者在完成写操作之前不允许其他读者或写者工作

- 写者执行写操作前，应让已有的读者和写者全部退出

```C
semaphore rw=1;//用于实现对文件的互斥访问。表示当前是否有进程在访问共享文件
int count=0;//记录当前有几个读进程在访问文件
semaphore mutex=1;//用于保证对count变量的互斥访问
semaphore w=1; //用于实现“写优先”
  
writer(){
  while(1){
    P（w）;
    P(rw); //写之前“加锁”
    写文件。。。
    V（rw);//写之后“解锁”
  V(w);
 }
}

reader(){
  while(1){
    P(w);
   P(mutex); //各读进程互斥访问count
    if(count==0) 
      P(rw); //第一个读进程的读进程数+1
    count++; //访问文件的读进程数+1
    V(mutex); 
    V(w);
    读文件...
    P(mutex); //各读进程互斥访问count
    count--; //访问文件的读进程数-1
    if(count==0)
      V(rw); //最后一个读进程负责“解锁”
    V(mutex);
 }
}
```

#### （5） 哲学家进餐问题

五个人，必须拿左右的筷子才能吃饭，避免死锁发生

解决方案：

- 可以对哲学家进程施加一些限制条件，比如最多允许四个哲学家同时进餐，这样可以保证至少有一个哲学家是可以拿到左右两只筷子的。
- 要求奇数号哲学家先拿左边的筷子，然后再拿右边的筷子，而偶数号哲学家刚好相反。用这种方法可以保证如果相邻的两个奇偶号哲学家都想吃饭，那么只会有其中一个可以拿起第一只筷子，另一个会直接阻塞。这就避免了占有一只后再等待另一只的情况。

- 仅当一个哲学家左右两只筷子都可用时才允许他抓起筷子。

```C
semaphore chopstick[5]={1,1,1,1,1};
semaphore mutex = 1; //互斥地取筷子
Pi(){     //i号哲学家的进程
  while(1){
    P(mutex);
    p(chopstick[i]);   //拿右
    p(chopstick[(i+1)%5]);//拿左
    V(mutex);
    吃饭...
    V(chopstick[i]);
    V(chopstick[(i+1)%5]);
    思考...
 }
}
```

## 2.4 死锁

### 2.4.1 死锁的概念

定义：多个进程因竞争资源而造成的一种僵局（互相等待/阻塞），各无法向前推进的现象

死锁产生原因：

- 对系统资源的竞争：系统资源有限，进程运行需要竞争系统资源
- 进程推进顺序非法：进程运行过程中请求和释放资源的顺序不当
- 信号量的使用不当：进程间彼此相互等待对方发来的消息情况，会使进程无法向前推进

死锁产生的必要条件

- 互斥条件：资源是独占的且排他使用，进程互斥使用资源，即任意时刻一个资源只能给一个进程使用，其他进程若申请一个资源，而该资源被另一进程占有时，则申请者等待直到资源被占有者释放。
- 不可剥夺条件：进程所获得的资源在未使用完毕之前，不被其他进程强行剥夺，而只能由获得该资源的进程资源释放。
- 请求和保持条件：进程每次申请它所需要的一部分资源，在申请新的资源的同时，继续占用已分配到的资源。
- 循环等待条件：在发生死锁时必然存在一个进程等待队列{P 1,P 2,…,P n},其中P 1等待P 2占有的资源，P 2等待P 3占有的资源，…，P n等待P 1占有的资源，形成一个进程等待环路，环路中每一个进程所占有的资源同时被另一个申请，也就是前一个进程占有后一个进程所有资源。

### 2.4.2 死锁的处理策略——预防死锁

设置某些限制条件，破坏产生死锁的四个必要条件的一个或多个，以防发生死锁

- 破坏互斥条件：把互斥的资源改造为共享资源，则系统不会进入死锁条件
  		部分资源不同共享，如打印机等临界资源只能互斥使用，不建议
- 破坏不剥夺条件：一个已占有的资源会被暂时释放，或被系统剥夺。常用于易保存和恢复的资源（CPU的寄存器及内存资源）
  		实现复杂，释放资源会造成之前工作失效
- 破坏请求和保持条件：采用预先静态分配方法，即进程在运行前一次申请完它所需要的全部资源，资源未满足前不允许运行
  		资源利用率极低，可能会导致某些进程饥饿
- 破坏循环等待条件：采用顺序资源分配法，对资源编号，进程按编号递增顺序请求资源
  		不方便增加新的设备，实际使用与递增顺序不一致，会导致资源的浪费，必须按规定次序申请资源

### 2.4.3 死锁的处理策略——避免死锁

在资源动态分配过程中，防止系统进入不安全状态，以避免发生死锁

#### （1） 系统安全状态

系统在进行进程资源分配之前，应先计算此次分配的安全性。若此次分配不会导致系统进入不安全状态，则允许分配，否则让进程等待

安全状态：系统能按某种进程推进顺序为每个进程分配其所需的资源，直至满足每个进程对资源的最大需求，是每个进程都可顺序完成，**这个进程推进顺序被称为安全序列**，若系统无法找到一个安全序列，则称系统处于不安全状态
		系统进入不安全状态不一定死锁，系统处于安全状态一定不死锁

#### （2） 银行家算法

银行家算法是荷兰学者 Dijkstra 为银行系统设计的，以确保银行在发放现金贷款时，不会发生不能满足所有客户需要的情况。后来该算法被用在操作系统中，用于避免死锁。 
**核心思想**：在进程提出资源申请时，先**预判**此次分配是否会导致系统进入不安全状态。如果会进入不安全状态，就暂时不答应这次请求，让该进程先阻塞等待

银行家算法步骤

1. 检查此次申请是否超过了之前声明的最大需求数

2. 检查此时系统剩余的可用资源是否还能满足这次请求

3. 试探着分配，更改各数据结构

4. 用安全性算法检查此次所分配是否会导致系统进入不安全状态


### 2.4.4 死锁的处理策略——检测和解除

系统为进程分配资源时不采取任何措施时需要提供死锁检测和解除的手段保证系统安全

#### （1） 死锁的检测

策略：

- 用某种数据结构（资源分配图）来保存资源的请求和分配信息
- 提供一种算法，利用上述信息来检测系统是否已进入死锁状态

资源分配图：
	圆圈：代表进程；方框：代表一类资源；框中的原点：代表一类资源中的一个资源
	由进程指向资源的箭头：请求边，表示该进程申请一个单位的该类资源
	由资源指向进程的箭头：分配边，表示该类资源已有一个资源分配给了该进程

<img src="C:/Users/Small Black/AppData/Roaming/Typora/typora-user-images/image-20240228164004800.png" alt="image-20240228164004800" style="zoom:67%;" />

上述资源分配图解析：进程P1已经分得了两个R1资源，并右请求一个R2资源；进程P2分得了一个R1资源和一个R2资源，并又请求了一个R1资源

死锁定理：

- 如果资源分配图中没有环路，则系统中没有死锁，如果图中存在环路则系统中可能存在死锁。
- 如果每个资源类中只包含一个资源实例，则环路是死锁存在的充分必要条件

资源分配图化简

- 找一个非孤立、只有分配边的进程结点，去掉分配边，将其变为孤立结点
- 再把相应的资源分配给一个等待该资源的进程，即将某进程的申请边变为分配边
- 重复以上步骤，若所有进程都可成为孤立结点，称该图是可完全简化的，否则称该图是不可完全简化的
  死锁状态的**充分条件**是：资源分配图是不可完全简化的

#### （2） 死锁的解除

以最小的代价解除死锁，恢复系统运行

- 资源剥夺法：挂起某些死锁进程，并抢占它的资源，将这些资源分配给其他的死锁进程

- 撤销进程法：强制撤销部分，甚至全部死锁进程，并剥夺这些进程的资源

- 进程回退法：让一个或多个死锁进程回退到足以避免死锁的地步
- 把每个死锁进程备份到前面定义的某个检查点，并重新启动所有进程

# 第三章 内存管理

## 3.1 内存管理基本内容

### 3.1.1 内存的基础知识

内存：由存储单元组成，每个地址对应一个存储单元，所有存储单元组成内存
		存储单元的大小：按字节编址 -> 一个存储单元为一字节；按字编址 -> 一个存储单元为一个字

#### （1） 进程运行的基本原理

- 指令的工作原理：指令的工作基于“地址”。 每个地址对应一个数据的存储单元
  		逻辑地址vs物理地址：逻辑地址就是相对地址
- 程序执行步骤：编辑(代码编写) -> 编译(源代码文件生成目标模块) -> 链接(标模块生成装入模块) -> 装入(装入模块装入内存)

- 三种链接方式：
  		a、静态链接：在程序运行前，先将各目标模块及它们所需的库函数连接成一个完整的可执行文件
       b、装入时动态链接：将各目标模块装入内存时，边装入边链接的链接方式
       c、运行时动态链接：在程序执行中需要该模块时，才将目标模块装入并进行链接，其优点时便于修改和更新
- 三种装入方式：
  		a、绝对装入:在编译的时候就知道程序放在内存的哪个位置
       b、静态重定位：装入时将逻辑地址转表为物理地址
       c、动态重定位：把地址转化推迟到程序真正要执行时才进行

### 3.1.2 内存管理的概念

操作系统对内存的划分和动态分配即为内存管理

#### （1） 内存空间的分配与回收

由操作系统完成主存储器空间的分配和管理，用户（程序员）不需要进行存储分配

#### （2） 内存空间的扩充

利用虚拟存储技术或自动覆盖技术，从逻辑上扩充内存

#### （3） 地址转换

程序中的逻辑地址与内存中的物理地址不一致时，要求存储管理需提供地址变换功能，将逻辑地址转换从物理地址

三种方式：

- 绝对装入：编译器负责地址转换（单道程序阶段，无操作系统）
- 可重定位装入：装入程序负责地址转换（早期多道批处理阶段）
- 动态运行时装入：运行时才进行地址转换（现代操作系统）

#### （4） 存储保护

保证各道作业在各自的存储空间内运行，互不干扰
		两种方式：设置上下限寄存器、采用重定位寄存器（基址寄存器）和界地址寄存器（限长寄存器）进行越界检查
*重定位寄存器中存放的是进程的起始物理地址。界地址寄存器中存放的是进程的最大逻辑地址*

### 3.1.3 内存空间的扩充

覆盖和交换技术是在多道程序环境下用来扩充内存的两种方法
		**区别：**覆盖是在同一个程序或进程中的；交换是在不同进程（或作业）之间的

#### （1） 覆盖

覆盖技术：将程序分为多个段，内存分为”固定区“和”覆盖区“，需要常驻的放在”固定区“，调入后就不再调出，不常用的段放在”覆盖区“，需要用到时调入内存，用不到时调出内存（必须由程序员声明覆盖结构，操作系统自动完成覆盖）

- 一个固定区：存放最活跃的程序端，固定区中的程序端在运行过程不会调入调出
- 若干覆盖区：不可能同时被访问程序段可共享一个覆盖区，覆盖区的程序段在运行过程中会根据需要调入调出

#### （2） 交换

交换技术：内存空间紧张时，系统将内存中某些进程暂时换出外存，把外存中某些已具备运行条件的进程换入内存（进程在内存与磁盘间动态调度）
		中级调度（内存调度），就是要决定将哪个处于挂起状态的进程重新调入内存

交换技术需要注意的内容：

- 具有对换功能的操作系统中，通常把磁盘空间分为**文件区**和**对换区**两部分。文件区主要用于存放文件，主要追求存储空间的利用率，因此对文件区空间的管理采用离散分配方式；对换区空间只占磁盘空间的小部分，被**换出的进程**数据就存放在对换区
  由于对换的速度直接影响到系统的整体速度，因此对换区空间的管理主要追求换入换出速度，因此通常对换区采用连续分配方式，对换区的I/O速度比文件区的更快
- 交换通常在许多进程运行且内存吃紧时进行，而系统负荷降低就暂停
- 可优先换出阻塞进程；可换出优先级低的进程；为了防止优先级低的进程在被调 入内存后很快又被换出，有的系统还会考虑进程在内存的驻留时间（PCB 会常驻内存，不会被换出外存）

### 3.1.4 内存空间的分配与回收

连续分配：为用户进程分配的必须是一个连续的内存空间；非连续分配：为用户进程分配的可以是一些分散的内存空间

#### （1） 连续分配方式

- 单一连续分配：内存被分配为系统区和用户区，系统区在低地址，用于存放操作系统相关数据；用户区用于存放用户进程相关数据，内存中只能有一道用户程序（只能单用户），用户程序独占用户区

- 固定分区分配：将用户内存空间分割为若干固定分区给各道程序，分割策略有分区大小相等和分区大小不相等两种；
  		分区说明表（一种数据结构）：管理各个分区来实现各个分区的分配与回收。每个表项对应一个分区，通常按分区大小排列。每个表项包括对应分区的大小、起始地址、状态（是否已分配）
- 动态分区分配：可变分区分配，不预先划分内存分区，而在进程装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要
  	常用的两种数据结构：
    					**空闲分区表**：每 个空闲分区对应 一个表项。表项 中包含分区号、 分区大小、分区 起始地址等信息
    					**空闲分区链**：每个分区的起始部分和末尾部分分别设置前向指 针和后向指针。起始部分处还可记录分区大小等信息

#### （2） 动态分区分配算法

##### 1、首次适应算法（First Fit)

算法思想：每次从低地址开始查找，找到第一个能满足大小的空闲分区
实现：空闲分区以地址递增的次序排列，每次分配内存时顺序查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区

##### 2、最佳适应算法(Best Fit)

算法思想：为了保证“大进程”到来时能有连续的大片区域，可以尽可能留下大片的空闲区，优先使用更小的空闲区
实现：空闲分区按容量递增次序链接。每次分配内存时顺序查找空闲分区链（或空闲分区 表），找到大小能满足要求的第一个空闲分区
*缺点：每次都选最小的分区进行分配，会留下越来越多的、很小的、难以利用的内存块。会产生很多的外部碎片*

##### 3、最坏适应算法(Worst Fit)

算法思想：可以在每次分配时优先使用最大的连续空闲区，这样分配后剩余的空闲区就不会太小，更方便使用
实现：空闲分区按容量递减次序链接，每次分配内存时顺序查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区
*缺点：每次都选最大的分区进行分配，虽然可以让分配后留下的空闲区更大，更可用，但会导致较大的连续空闲区被迅速用完。如果之后有“大进程”到达，就没有内存分区可用了*

##### 4、领近适应算法(Next Fit)

算法思想：每次从上次查找结束的位置开始检索

实现：空闲分区以地址递增的顺序排列（可排成一个循环链表）。每次分配内存时从上次查找结束的位置开始查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区
*缺点：可能会导致无论低地址、高地址部分的空闲分区都有相同的概率被使用，也就导致了高地址部分的大分区更可能被使用，划分为小分区，最后导致无大分区可用*

#### （3） 非连续分配管理方式

非连续分配允许一个程序分散地装入不相邻的内存分区

非连续分配管理方式根据分区的大小是否固定，分为分页存储管理方式和分段存储管理方式，在分页存储管理方式中，有根据运行作业的所有页面都装入内存才能运行，分为基本分页存储管理方式和请求分页存储管理方式

##### 1、基本分页存储管理

**分页思想**：把主存空间划分为大小相等且固定的块，块相对较小，作为主存的基本单位。每个进程也以块为单位进行划分，进程在执行时，以块为单位逐个申请主存中的块空间

**分页存储**：将内存空间分为一个个大小相等的分区（比如：每个分区 4KB），每个分区就是一个“**页框**”（**页框=页帧=内存块=物理块=物理页面**）。每个页框有一个编号，即“页框号”（**页框号=页帧号=内存块号=物理块号=物理页号**），页框号从0开始

- 将进程的逻**辑地址空间**也分为与页框大小相等的一个个部分， 每个部分称为一个“页”或“页面” 。每个页面也有一个编号， 即“**页号**”，页号也是从0开始
- 操作系统**以页框为单位**为各个进程分配内存空间。进程的每个页面分别放入一个页框中。也就是说，进程的页面与内存的页框有一一对应的关系

**页表**：一种数据结构，为了能知道进程的每个页面在内存中存放的位置，操作系统要为每个进程建立一张页表
	1、一个进程对应一张页表
    2、进程的每个页面对应一个页表项 
	3、每个页表项由“页号”和“块号”组成 
	4、页表记录进程页面和实际存放的内存块之间的映射关系
	5、每个页表项的长度是相同的

**地址转换**：（如果每个页面 大小为 2的k次方B，用二进制数表示逻辑地址， 则末尾 K 位即为页内偏移量，其余部分就是页号）
			**页号** = 逻辑地址 / 页面长度 （取除法的整数部分） 
			**页内偏移量** = 逻辑地址 % 页面长度（取除法的余数部分）
	例子：逻辑地址 2，用二进制表示应该是 0000 0000 0000 0000 0000 0000 0000 0010 
	页号 = 2/4096 = 0 = 0000 0000 0000 0000 0000，页内偏移量 = 2 % 4096 = 2 = 0000 0000 0010

**逻辑地址结构**

分页存储管理的逻辑地址结构如下所示：

| 31       ········       12 | 11       ········       0 |
| :------------------------: | :-----------------------: |
|           页号P            |        页内偏移量W        |

地址结构包含两个部分：前一部分为页号，后一部分为页内偏移量 W。在上图所示的例子中，地址长度为 32 位，其中 0~11位 为“页内偏移量”，或称“页内地址” ；12~31 位为“页号”
如果有 K 位表示“页内偏移量”，则说明该系统中一个页面的大小是 2的K次方个内存单元，如果有 M 位表示“页号”，则说明在该系统中，一个进程最多允许有 2的M次方个页面

##### 2、 基本分段存储管理方式

a、**分段**：段式管理方法按照用户进程中的自然段划分逻辑空间

进程的地址空间： 按照程序自身的逻辑关系划分为若干个段，每段有段名，每段从0开始编址
内存分配规则：    以段为单位进行分配，每个段在内存中占据连续空间，但各段之间可以不相邻

分段系统的逻辑结构由段号（段名）和段内地址（段内偏移量）所组成
	**段号**的位数决定了每个进程最多可以分几个段；	**段内地址位数**决定了每个段的最大长度是多少

b、**段表**

段表：程序分多个段，各段离散地装入内存，为了保证程序能正常运行，就必须能从物理内存中 找到各个逻辑段的存放位置。为此，需为每个进程建立**一张段映射表**，简称“段表”

每个程序被分段后，用段表记录该程序在内存中存放的位置

段表的内容包含：段号 段长 基址 ；配置段表后，执行中的进程可通过查找段表，找到每段所对应的内存区（**逻辑到物理的映射过程**）

c、地址变换机构

为实现进程从逻辑地址到物理地址的变换功能，在系统中设置了段表寄存器，用于存放段表始址和段表长度
<img src="C:/Users/Small Black/AppData/Roaming/Typora/typora-user-images/image-20240302150851388.png" alt="image-20240302150851388" style="zoom:50%;" />

分段系统的地址变换过程如下分析图
<img src="C:/Users/Small Black/AppData/Roaming/Typora/typora-user-images/image-20240302151202673.png" alt="image-20240302151202673" style="zoom:50%;" />

##### 3、分段、分页管理的对比

**页**是信息的物理单位。分页的主要目的是为了实现离散分配，提高内存利用率。分页仅仅是系统管理上的需要，完全是系统行为，对用户是不可见的
**段**是信息的逻辑单位。分段的主要目的是更好地满足用户需求。一个段通常包含着一组属于一个逻辑模块的信息。分段对用户是可见的，用户编程时需要显式地给出段名
		*页的大小固定且由系统决定。段的长度却不固定，决定于用户编写的程序*

**分页**的用户进程地址空间是一维的，程序员只需给出一个记忆符即可表示一个地址
**分段**的用户进程地址空间是二维的，程序员在标识一个地址时，既要给出段名，也要给出段内地址

分段比分页更容易实现**信息的共享和保护**。不能被修改的代码称为纯代码或可重入代码（不属于临 界资源），这样的代码是可以共享的。可修改的代码是不能共享的

逻辑地址的访存次数：
	分页（单级页表）：第一次访存——查内存中的页表，第二次访存——访问目标内存单元。总共两次访存 
	分段：第一次访存——查内存中的段表，第二次访存——访问目标内存单元。总共两次访存 
与分页系统类似，分段系统中也可以引入快表机构，将近期访问过的段表项放到快表中，这样可以少一次访问，加快地址变换速度

## 3.2 虚拟内存管理

### 3.2.1 虚拟内存的基本概念

#### （1） 传统存储管理方式的特征、缺点

- 一次性：作业必须一次性全部装入内存后才能开始运行。这会造成两个问题：作业很大时，不能全部装入内存，导致大作业无法运行；当大量作业要求运行时，由于内存无法容纳所有作业，因此只有少量作业能运行，导致多道程序并发度下降
- 驻留性：一旦作业被装入内存，就会一直驻留在内存中，直至作业运行结束。事实上，在一个时间段内，只需要访问作业的一小部分数据即可正常运行，这就导致了内存中会驻留大量的、暂时用不到的数据

#### （2） 局部性原理

- 时间局部性：如果执行了程序中的某条指令，那么不久后这条指令很有可能再次执行；如果某个数据被访问过，不久之后该数据很可能再次被访问（因为程序中存在大量的循环）
- 空间局部性：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也很有可能被访问（因为很多数据在内存中都是连续存放的，并且程序的指令也是顺序地在内存中存放的）
- 高速缓存技术：将近期会频繁访问到的 数据放到更高速的存储 器中，暂时用不到的数 据放在更低速存储器中

#### （3） 虚拟内存的定义和特征

基于局部性原理，在程序装入时，可以将程序中很快会用到的部分装入内存，暂时用不到的部分留在外存， 就可以让程序开始执行。 在程序执行过程中，当所访问的信息不在内存时，由 操作系统负责将所需信息从外存调入内存，然后继续执行程序。 若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存。 在操作系统的管理下，在用户看来有一个比实际内存大得多的内存，这就是**虚拟内存**

虚拟内存最大容量是计算机地址结构确定的，虚拟内存的实际容量=min(内存和外存容量之和，CPU寻址范围)

虚拟内存的特征：

- 多次性：无需在作业运行时一次性全部装入内存，而是允许被分成多次调用内存

- 对换性：在作业运行时无需一直常驻内存，而是允许在作业运行过程中，将作业换入换出

- 虚拟性：从逻辑上扩充了内存的容量，使用户看到的内存容量，远大于实际的容量


#### （4） 如何实现虚拟内存技术

虚拟内存技术，允许一个作业分多次调入内存。如果采用连续分配方式，会不方便实现。因此， 虚拟内存的实现需要建立在离散分配的内存管理方式基础上

实现方式：

- 请求分页存储管理
- 请求分段存储管理
- 请求段页式存储管理

### 3.2.2 请求分页管理方式

请求分页存储管理与基本分页存储管理的主要区别： 
在程序执行过程中，当所访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存，然后继续执行程序。 若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存

#### （1） 页表机制

与基本分页管理相比，请求分页管理中，为了实现“请求调页”，操作系统需要知道每个页面是否已经调入内存；如果还没调入，那么也需要知道该页面在外存中存放的位置

请求分页系统中的页表项结构如下：
![image-20240302154123929](C:/Users/Small Black/AppData/Roaming/Typora/typora-user-images/image-20240302154123929.png)

状态位：标志是否已调入内存
访问字段：可记录最近被访问过几 次，或记录上次访问的时间，供置换算法选择换出页面时参考
修改位：页面调入内 存后是否被修改过
外存地址：页面在外存中的存放位置

#### （2） 缺页中断机构

在请求分页系统中，每当要访问的页面不在内存时，便产生一个缺页中断，然后由操作系统的缺页中断处理程序处理中断，此时缺页的进程阻塞，放入阻塞队列，调页完成后再将其唤醒，放回就绪队列
		如果内存中有空闲块，则为进程分配一个空闲块，将所缺页面装入该块，并修改页表中相应的页表项
		如果内存中没有空闲块，则由页面置换算法选择一个页面淘汰，若该页面在内存期间被修改过，则要将其写回外存。未修改过的页面不用写回外存

缺页中断简介：
		缺页中断是因为当前执行的指令想要访问的目标页面未调入内存而产生的，因此**属于内中断** 
		一条指令在执行期间，可能产生多次缺页中断

#### （3） 地址变换机构

在进行地址变换时，先检索快表：
		若找到要访问的页，则修改该页表项中的访问位，然后利用页表项中给出的物理块号和页内地址形成物理地址
		若未找到该页的页表项，则到内存中查找页表，再对比页表项中的状态位，查看该页是否已调入内存，未调入则产生缺页中断，请求从外存把该页调入内存；

请求分页中的地址变换过程如下图所示：

<img src="C:/Users/Small Black/AppData/Roaming/Typora/typora-user-images/image-20240302160112920.png" alt="image-20240302160112920" style="zoom:50%;" />

### 3.2.3 页面置换算法

**最佳**置换算法(OPT)：每次选择淘汰的页面将是以后永不使用，或者在最长时间内不再被访问的页面，可保证最低的缺页率
实际上，只有在进程执行的过程中才能知道接下来会访问到的是哪个页面。操作系统无法提前预判页面访问序列。因此，最佳置换算法是**无法实现的**

**先进先出**置换算法(FIFO)：优先淘汰最先进入内存的页面
实现方法：把调入内存的页面根据调入的先后顺序排成一个队列，需要换出页面时选择队头页面即可。 队列的最大长度取决于系统为进程分配了多少个内存块
		Belady 异常——当为进程分配的物理块数增大时，缺页次数不减反增的异常现象（FIFO会产生该异常）

**最近最久未使用**置换算法(LRU)：优先淘汰最近最久没访问的页面
实现方法：赋予每个页面对应的页表项中，用访问字段记录该页面自上次被访问以来所经历的时间t。 当需要淘汰一个页面时，选择现有页面中 t 值最大的，即最近最久未使用的页面

时钟置换算法(CLOCK)：一种性能和开销较均衡的算法，又称CLOCK算法，或最近未用算法(NRU，Not Recently Used)
简单实现方法：为每个页面设置一个访问位，再将内存中的页面都通过链接指针链接成一个循环队列。当某页被访问时，其访问位置为1。当需要淘汰一个页面时，只需检查页的访问位。 如果是0，就选择该页换出；如果是1，则将它置为0，暂不换出，继续检查下一个页面，若第一轮扫描中所有页面都是1，则将这些页面的访问位依次置为0后，再进行第二轮扫描（第二轮扫描中一定会有访问位为0的页面，因此简单的CLOCK 算法选择一个淘汰页面最多会经过两轮扫描）

改进型的时钟置换算法：在其他 条件都相同时，应优先淘汰没有修改过的页面，避免I/O操作

### 3.2.4 页面分配策略

#### （1） 驻留集

指请求分页存储管理中给进程分配的物理块的集合

在采用了虚拟存储技术的系统中，驻留集大小一般小于进程的总大小
驻留集太小，会导致缺页频繁，系统要花大量的时间来处理缺页，实际用于进程推进的时间很少
驻留集太大，又会导致多道程序并发度下降，资源利用率降低。所以应该选择一个合适的驻留集大小

#### （2） 页面分配、置换策略

**固定分配局部替换**：系统为每个进程分配一定数量的物理块，在整个运行期间都不改变。若进程在运行中发生缺页，则只能从该进程在内存中的页面中选出一页换出，然后再调入需要的页面。
缺点：很难在刚开始就确定应为每个进程分配多少个物理块才算合理。（采用这种策略的系统可以根据进程大小、优先级、或是根据程序员给出的参数来确定为一个进程分配的内存块数）

**可变分配全局替换**：刚开始会为每个进程分配一定数量的物理块。操作系统会保持一个空闲物理块队列。当某进程发生缺页时，从空闲物理块中取出一块分配给该进程；若已无空闲物理块，则可选择一个未锁定的页面换出外存，再将该物理块分配给缺页的进程
采用这种策略时，只要某进程发生缺页， 都将获得新的物理块，仅当空闲物理块用完时，系统才选择一个未锁定的页面调出。被选择调出的页可能是系统中任何一个进程中的页，因此这个被选中的进程拥有的物理块会减少，缺页率会增加

**可变分配局部替换**：刚开始会为每个进程分配一定数量的物理块。当某进程发生缺页时，只允许从该进程自己的物理块中选出一个进行换出外存。如果进程在运行中频繁地缺页，系统会为该进程多分配 几个物理块，直至该进程缺页率趋势适当程度；反之，如果进程在运行中缺页率特别低，则可适当减少分配给该进程的物理块

#### （3） 调入页面的时机

预调页策略：根据局部性原理，一次调入若干个相邻的页面可能比一次调入一个页面更高效。但如果提前调入的页面中大多数都没被访问过，则又是低效的。因此可以预测不久之后可能访问到的页面，将它们预先调入内存，但目前预测成功率只有50%左右。故这种策略主要用于进程的首次调入， 由程序员指出应先调入哪些部分

请求调页策略：进程在运行期间发现缺页时才将所缺页面调入内存。由这种策略调入的页面一定会被访问到，但由于每次只能调入一页，而每次调页都要磁盘I/O操作，因此I/O开销较大

#### （5） 从何处调页

系统拥有**足够的对换区空间**：页面的调入、调 出都是在内存与对换区之间进行，这样可以保 证页面的调入、调出速度很快。在进程运行前， 需将进程相关的数据从文件区复制到对换区

系统缺少**足够的对换区空间**：凡是不会被修改 的数据都直接从文件区调入，由于这些页面不 会被修改，因此换出时不必写回磁盘，下次需 要时再从文件区调入即可。对于可能被修改的 部分，换出时需写回磁盘对换区，下次需要时 再从对换区调入

UNIX 方式：运行之前进程有关的数据全部放在文件区，故未使用过的页面，都可从文件区调入。若被使用过的页面需要换出，则写回对换区，下次需要时从对换区调入

#### （6） 抖动（颠簸）现象

刚刚换出的页面马上又要换入内存，刚刚换入的页面马上又要换出外存，这种频繁的页面调度行为称为抖动，或颠簸
	产生抖动的主要原因是进程频繁访问的页面数目高于可用的物理块数（分配给进程的物理块不够）

#### （6） 工作集

指在某段时间间隔里，进程实际访问页面的集合

工作集大小可能小于窗口尺寸，实际应用中，操作系统可以统计进程的工作集大小，根据工作集大小给进程分配若干内存块。如：窗口尺寸为5，经过一段时间的监测发现某进程的工作集最大为3，那么说明该进程有很好的局部性，可以给这个进程分配3个以上的内存块即可满足进程的运行需要。 一般来说，驻留集大小不能小于工作集大小，否则进程运行过程中将频繁缺页

# 第四章 文件管理

## 4.1 文件系统基本内容

### 4.1.1 初识文件管理

文件的定义：就是一组有意义的信息/数据集合

文件的属性：
	文件名：由创建文件的用户决定文件名，主要是为了方便用户找到文件，同一目录下不允许有重名文件
	标识符：一个系统内的各**文件标识符唯一**，对用户来说毫无可读性， 因此标识符只是操作系统用于区分各个文件的一种内部名称
	类型：指明文件的类型 
	位置：文件存放的路径（让用户使用）、在外存中的地址（操作系统使用，对用户不可见） 
	大小：指明文件大小创建时间、上次修改时间文件所有者信息 
	保护信息：对文件进行保护的访问控制信息

### 4.1.2 文件的逻辑结构

#### （1） 无结构文件

文件内部的数据就是一系列二进制流或字符流组成。又称“流式文件”。如： Windows 操作系统中的`.txt` 文件。

#### （2） 有结构文件（记录式文件）

由一组相似的记录组成，又称“记录式文件”。每条记录又若干个数据项组成。如： 数据库表文件。一般来说，每条记录有一个数据项可作为关键字（作为识别不同记录的ID）

在逻辑结构上常分三类

- 顺序文件：文件中的记录顺序排列（逻辑上），记录可以是定长的或可变长的。各个记录在物理上可以顺序存储或链式存储
  	按照是否与关键字顺序有关，可以分为串结构（记录之间的顺序与关键字无关）和顺序结构（记录之间的顺序按关键字顺序排列）
- 索引文件：除了文件本身(称做数据区)之外,另建立一张指示逻辑记录和物理记录之间一一对应关系的表——索引表。这类包括文件数据区和索引表两大部分的文件称做索引文件
- 索引顺序文件：索引文件和顺序文件思想的结合。索引顺序文件中，同样会为文件建立一张索引表，但不同的是：并不是每个记录对应一个索引表项，而是一组记录对应一个索引表项


### 4.1.3 文件目录

#### （1） 文件控制块（FCB）

文件控制块（FCB）：是用来存放控制文件需要的各种信息的数据结构

FCB 的有序集合称为“文件目录”，一个FCB就是一个文件目录项。 FCB 中包含了文件的**基本信息**（文件名、物理地址、逻辑结构、物理结构等），**存取控制信息**（是否可读/可写、禁止访问的用户名 单等），**使用信息**（如文件的建立时间、修改时间等）

#### （2） 目录结构

1、单级目录结构：单级目录实现了“按名存取”，但是不允许文件重名（不适用多用户操作系统）

2、两级目录结构：分为主文件目录（MFD，Master File Directory）和用户 文件目录（UFD，User File Directory）两级目录结构允许不同用户的文件重名，也可 以在目录上实现实现访问限制，但不能对文件进行分类
		主文件目录：主文件目录记录用户名及相 应用户文件目 录的存放位置
		用户文件目录：用户文件目录由该用户的文件FCB组成

3、多级目录结构（树形目录结构）
	用户（或用户进程）要访问某个文件时要用文件路径名标识文件，文件路径名是个字符串。各级目录之间用“/”隔开。从根目录出发的路径称为绝对路径

​	系统根据绝对路径一层一层地找到下一级目录。刚开始从外存读入根目录的目录表；找到指定目录的存放位置后，从外存读入对应的目录表；再找到下一级目录的存放位置，再从外存读入对应目录表；每次过程需要读磁盘I/O操作；在 Linux 中，“.”表示当前目录
​				*当代操作系统采用方法、不便于文件共享*

4、无环图目录结构

​    可以用不同的文件名指向同一个文件，甚至可以指向同一个目录（共享同一目录下的所有内容）
​	需要为每个共享结点设置一个共享计数器，用于记录此时有多少个地方在共享该结点。用户ᨀ出删除结 点的请求时，只是删除该用户的FCB、并使共享计数器减1，并不会直接删除共享结点

#### （3） 索引节点（对文件控制块）

除文件名之外的所有信息都放到索引节点中，每个文件对应一个所有节点
目录项中只包含文件名，索引节点指针，因此每个目录项的长度大幅减少
由于目录项长度减少，因此每个磁盘可以存放更多个目录项，因此检索文件时磁盘IO的次数会减少

### 4.1.4 文件的物理结构（文件分配方式）

常用的磁盘非陪方式有三种：连续分配、链接分配和索引分配

#### （1） 连续分配

连续分配方式要求每个文件在磁盘上占有一组连续的块；连续分配的文件在顺序读/写时速度最快
用户给出要访问的逻辑块号，操作系统找到该文件对应的目录项（FCB） 物理块号 = 起始块号 + 逻辑块号
（在外存管理中，文件的逻辑地址空间也被分为了一个一个的**文件“块”**文件的逻辑地址也可以表示为（逻辑块号，块内地址）的形式）

优缺点：物理上采用连续分配， 存储空间利用率低，会产生难以利用的磁盘碎片 可以用紧凑来处理碎片，但需耗费很大的时间代价

#### （2） 链接分配

链接分配采取离散分配的方式，可以为文件分配离散的磁盘块。分为隐式链接和显式链接两种

- **隐式链接**：除文件最后一个盘块外，每个盘块中都存有指向下一个盘块的指针。文件目录包括文件第一块的指针和最后一块的指针。 
  	优点：很方便文件拓展，不会有碎片问题，外存利用率高
  	缺点：只支持顺序访问，不支持随机访问，查找效率低，指向下一个盘块的指针也需要耗费少量的存储空间
- **显式链接**：把用于链接文件各物理块的指针显式地存放在一张表中，即 文件分配表（FAT，File Allocation Table）。一个磁盘只会建立一张文件分配表。开机时文件分配表放入内存，并常驻内存
      优点：方便文件拓展，不会有碎片问题，外存利用率高，支持随机访问。地址转换时不需要访问磁盘，文件的访问效率更高
      缺点：文件分配表的需要占用一定的存储空间

#### （3） 索引分配

索引分配允许文件离散地分配在各个磁盘块中，系统会为每个文件建立一张索引表，索引表中记录了文件的各个逻辑块对应的物理块
	索引表的功能类似于内存管理中的页表——建立逻辑页面到物理页之间的映射关系
	索引表存放的磁盘块称为索引块。文件数据存放的磁盘块称为数据块

在文件较大情况下有三种解决方法

- 链接方案：索引表太大，可以将多个索引块链接起来存放。缺点：会导致磁盘I/O次数过多，查找效率低下
- 多层索引：建立多层索引（原理类似于多级页表）。使第一层索引块指向第二层的索引块。还可根据文件大小的要求再建立第三层、第四层索引块。采用 K 层索引结构，且顶级索引表未调入内存，则访问 一个数据块只需要 K + 1 次读磁盘操作
          缺点：即使是小文件，访问一个数据块依然需要K+1次读磁盘
- 混合索引：多种索引分配方式的结合。例如，一个文件的顶级索引表中，既包含直接地址索引（直接 指向数据块），又包含一级间接索引（指向单层索引表）、还包含两级间接索引（指向两层索引表） 
          优点：对于小文件来说，访问一个数据块所需的读磁盘次数更少

总结：

<img src="C:/Users/Small Black/AppData/Roaming/Typora/typora-user-images/image-20240310161630102.png" alt="image-20240310161630102" style="zoom:50%;" />

### 4.1.5 文件管理

#### （1） 文件存储空间管理

1、存储空间的划分与初始化

- 文件卷（逻辑卷）的概念
- 目录区与文件区

2、几种管理方法

- 空闲表法：首位置+长度，回收时注意修改
- 空闲链表法（空闲盘块链、空闲盘区链）
- 位示图法
- 成组链接法：文件卷的目录区中专门用一个磁盘块作为超级块，当系统启动时需要将超级内存块读入内存。并且保证内存与外存中的超级块数据一致。

#### （2） 文件的基本操作

- 创建文件（create）：在外存中找到文件所需的空间 -> 创建该文件对应的目录项

- 删除文件(delete)：找到文件名对应的目录项 -> 回收文件占用的磁盘块 -> 删除文件对应的目录项

- 读文件(read)：操作系统在处理read系统调用时，会从读指针指向的外存中，将用户指定大小的数据读入用户指定的内存区域中

- 写文件(write)：操作系统在处理write系统调用时，会从用户指定的内存区域中，将指定大小的数据歇会写指针指向的外存

- 打开文件(open)：找到文件名对应的目录项 -> 将目录项复制到内存中的“打开文件”中

- 关闭文件(close)：将进程的打开文件表相应表项删除 -> 回收分配给该文件的内存空间等资源 -> 打开文件表，删除对应表项


#### （3） 文件共享

- 基于索引结点的共享方式（硬链接）：直接指向文件的索引节点
- 基于符号链的共享方式（软链接）：相当于windows的快捷方式

#### （4） 文件保护

- 口令保护：为文件设置一个“口令”，用户请求访问该文件时必须提供“口令”
- 加密保护：使用某个“密码”对文件进行加密，在访问文件时需要提供正确的“密码”才能对文件进行正确的解密
- 访问控制：在每个文件的FCB（或索引节点）中增加一个访问控制列表，该表记录各个用户对该文件执行的操作


## 4.2 磁盘的组织与管理

### 4.2.1 磁盘的结构

- 磁盘：表面由磁性物质组成，可用来记录二进制数据
- 磁道：磁盘的盘面被划分为一个个圆形的圈，这样的一个圈就是一个磁道
- 扇区：磁盘读写的基本存储单位
- 磁盘中读写数据：磁盘旋转的过程中，指定的扇区会从磁头下面划过，这样就完成了对指定扇区的读/写
- 盘面柱面：每个盘面对应一个磁头。所有的磁头都是连在同一个磁臂上的，因此所有磁头只能“共进退”。所有盘面中相对位置相同的磁道组成柱面

### 4.2.2 磁盘调度算法

1、一次磁盘读/写操作需要的时间（s：启动磁头臂的时间；m：磁头跨越一个磁道的时间；n：跨越磁道的数量）

- 寻找时间 Ts = s + m * n
- 延迟时间Tr = 1 / ( 2 * r)；1 / r：转一圈需要的时间
- 传输时间Tt = b / ( r * N )；b：读写的字节数；N：每个磁道上的字节数

2、磁盘调度算法

- 先来先服务（FCFS）：根据进程请求访问磁盘的先后次序进行调度
- 最短寻找时间优先（SSTF）：其要求访问的磁道与当前磁头所在的磁道距离最近，以使每次的寻道时间最短，但这种调度算法却不能保证**平均寻道时间**最短

- 扫描算法（SCAN）：当磁头正在由里向外移动时，SCAN算法所选择的下一个访问对象应是其欲访问的磁道，既在当前磁道之外，又是距离最近的。这样由里向外地访问，直至再无更外的磁道需要访问时，才将磁臂换向，由外向里移动。也叫电梯算法

- 循环扫描算法（C-SCAN）：为了减少SCAN算法造成的某些进程的请求被严重推迟，CSCAN算法规定磁头单向移动

### 4.2.3 减小磁盘延迟时间的方法

- 在一个盘面上可以通过交错编号来减少连续读取所需的延迟时间
  		交替编号策略，即让逻辑上相邻的扇区在物理上有一定的间隔。可以使读取连续的逻辑扇区所需的延迟时间更小
- 不同盘面的相同位置可以通过错位命名来减少所需的延迟时间

### 4.2.4 磁盘的管理

1、磁盘初始化

低级格式化（物理分区）：新磁盘在存储数据之前，它必须分成扇区以便磁盘控制器能进行读和写操作
	扇区数据结构：头、数据区域（通常为512 B大小）和尾组成

2、引导块

自举程序：启动时的一个初始化程序，用于初始化CPU、寄存器、设备控制器和内存等，然后启动操作系统

3、坏块的管理

对于简单硬盘：手工处理
复杂磁盘：控制器用可用备块来逻辑地替代坏块（扇区备用）

# 第五章 I/O（输入/输出）管理

## 5.1 I/O管理基本内容

### 5.1.1 I-O设备的概念和分类

I/O 设备：可以将数据输入到计算机，或者可以接收计算机输出数据的外部设备，属于计算机中的硬件部件

分类：
	-- 按使用特性分类：人机交互的外部设备、存储设备、网络通信设备
	-- 按传输速率分类：低速设备、中速设备、高速设备
	-- 按信息交换的单位分类：块设备、字符设备

### 5.1.2 I-O控制器

主要功能：接受和识别CPU发出的命令（控制寄存器）、向CPU报告设备的状态（状态寄存器）、进行数据交换（数据寄存器）

组成：
	--- CPU与控制器之间的接口，实现控制器与CPU之间的通信
	--- I/O逻辑，负责识别CPU发出的命令，并向设备发出命令
	--- 控制器与设备之间的接口，实现可攻至其与设备之间的通信

两种寄存器编址方式：
	--- 内存映射I/O，控制器中的寄存器与内存地址统一编址
	--- 寄存器独立编制，控制器中的寄存器使用独立的地址

### 5.1.3 I-O控制方式

1、程序直接控制方式

计算机从外部设备读取数据到存储器，每次读一个字的数据。对读入的每个字， CPU 需要对外设状态进行循环检查，直到确定该字已经在I/0 控制器的数据寄存器中。在程序直接控制方式中，由于CPU 的高速性和I/0设备的低速性，致使CPU 的绝大部分时间都处于等待I/0 设备完成数据I/0 的循环测试中，造成了CPU 资源的极大浪费。在该方式中， CPU 之所以要不断地测试I/0 设备的状态，就是因为在CPU 中未采用中断机构，使I/0 设备无法向CPU报告它已完成了一个字符的输入操作

<img src="C:/Users/Small Black/AppData/Roaming/Typora/typora-user-images/image-20240322162509914.png" alt="image-20240322162509914" style="zoom:33%;" />

2、中断驱动方式

思想：允许I/0 设备主动打断CPU 的运行并请求服务，从而“解放"CPU, 使得其向I/0 控制器发送读命令后可以继续做其他有用的工作

<img src="C:/Users/Small Black/AppData/Roaming/Typora/typora-user-images/image-20240322162533920.png" alt="image-20240322162533920" style="zoom: 33%;" />

3、DMA方式：直接存储器存取

工作过程： CPU 接收到I/O 设备的DMA 请求时，它给I/0 控制器发出一条命令，启动DMA 控制器，然后继续其他工作。之后CPU 就把控制操作委托给DMA 控制器，由该控制器负责处理。DMA 控制器直接与存储器交互，传送整个数据块，每次传送一个字，这个过程不需要CPU 参与。传送完成后，DMA 控制器发送一个中断信号给处理器。因此只有在传送开始和结束时才需要CPU的参与(预处理【设置CR、MAR、DC等】和后处理【中断处理、唤醒因该I/O阻塞的进程程等】)

<img src="C:/Users/Small Black/AppData/Roaming/Typora/typora-user-images/image-20240322162630000.png" alt="image-20240322162630000" style="zoom:33%;" />



4、I/O通道控制方式

I/O通道方式是DMA方式的发展，它可以进一步 减少CPU的干预，即把对一个数据块的读（或写）为单位的干预，减少为对一组数据块的读（或写）及有关控制和管理为单位的干预。同时，又可以实现CPU、通道和I/0 设备三者的并行操作，从而更有效地提高整个系统的资源利用率

## 5.2 I/O软件层次结构

I/O软件层次结构可分为以下五层

<img src="C:/Users/Small Black/AppData/Roaming/Typora/typora-user-images/image-20240322162955844.png" alt="image-20240322162955844" style="zoom:50%;" />

1、用户层软件：用户层软件实现了与用户交互的接口，用户可直接使用该层提供的、与I/O操作相关的库函数对设备进行操作

2、设备独立性软件（设备无关性软件）

又称设备无关性软件。与设备的硬件特性无关的功能几乎都在这一层实现
用于实现用户程序与设备驱动器的统一接口、设备命令、设备保护，以及设备分配与释放等

主要功能：
	-- 向上层提供统一的调用接口（如 read/write 系统调用）
	-- 设备的保护，原理类似与文件保护
	-- 差错处理，设备独立性软件需要对一些设备的错误进行处理
	-- 设备的分配与回收
	-- 数据缓冲区管理，可以通过缓冲技术屏蔽设备之间数据交换单位大小和传输速度的差异
	-- 建立逻辑设备名到物理设备名的映射关系；根据设备类型选择调用相应的驱动程序

3、设备驱动程序（比如打印机驱动）：与硬件直接有关，用来具体实现系统对设备发出的操作指令，驱动I/O设备工作

4、中断处理程序：用于保存被中断进程的CPU环境，转入相应的中断处理程序进行处理，处理完后恢复现场，并返回到被中断的进程

5、硬件：执行IO操作，有机械部件、电子部件组成

## 5.3 假脱机技术

为了缓和CPU的高速型与IO设备低速性之间的矛盾而引入了脱机输入、脱机输出技术。该技术是利用专门的外围控制机，将低速IO设备上的数据传送到高速磁盘上；或者相反

脱机技术：脱离主机的控制进行输入/输出控制
假脱机技术：又称“SPOOLing技术”，用软件的方式模拟脱机技术

SPOOLing的意思是外部设备同时联机操作，又称为假脱机输入输出操作，是操作系统中采用的一项将独占设备改造成共享设备的技术

SPOOLing系统：必须要有多道程序并发进行

2、假脱机技术的实现原理

- 输入井和输出井
- 输入进程和输出进程
- 输入缓冲区和输出缓冲区

<img src="C:/Users/Small Black/AppData/Roaming/Typora/typora-user-images/image-20240322164955920.png" alt="image-20240322164955920" style="zoom: 50%;" />

- 在磁盘上开辟出的两个存储区域。输入井模拟脱机输入时的磁盘，用于收容IO设备输入的数据。输出井模拟脱机输出的磁盘，用于收容用户程序的输出数据
- 在内存中开辟的两个缓冲区。出入缓冲区用于暂存由输入设备送来的数据，以后再传送到输入井。输出缓冲区用于暂存从输出井送来的数据，以后再传送到输出设备
- 输入进程模拟脱机输入时的外围控制机，将用户要求的数据从输入机通过输入缓冲区再送到输入井。当CPU需要输入数据时，直接将数据从输入井读入内存。输入进程模拟脱机输出时的外围控制机，把用户要求输出的数据先从内存送到输出井，待输出设备空闲时，再将输出井中的数据经过输出缓冲区送到输出设备

共享打印机是使用SPOOLing技术的一个实例，当用户进程请求打印输出时，SPOOLing系统同意为它打印输出，但并不真正立即把打印机分配给该用户进程，而只为它做两件事：

　　1）由输出进程在输出井中为之申请一个空闲磁盘块区，并将要打印的数据送入其中。
　　2）输出进程再为用户进程申请一张空白的用户请求打印表，并将用户的打印要求填入其中，再将该表挂到请求打印队列中。

SPOOLing系统的特点是：提高了IO速度；将独占设备改造为共享设备；实现了虚拟设备功能

## 5.4 设备的分配与回收

设备分配的基本任务是根据用户的IO请求，为他们分配所需的设备

**1、设备的分类**

独占设备，讲一个设备分配给某进程后，便又该进程独占，直至该进程完成或释放该设备
共享设备，可以同时分配给多个进程使用，但需要对这些进程访问该设备的先后次序进程合理的调度
虚拟设备属于可共享设备，可以将它同时分配给多个进程使用

**2、设备分配依据**

设备分配依据的主要数据结构有设备控制表（DCT）、控制器控制表（COCT）、通道控制表（CHCT）和系统设备表（SDT），各数据结构功能如下：

- 设备控制表：系统为每一个设备配置一张DCT，它用于记录设备的特性以及与IO控制器连接的情况。DCT包括设备标示符、设备类型、设备状态、指向COUCT的指针等。其中，设备队列指针指向等待使用该设备的进程组成的等待队列，控制表指针指向于该设备相连接的设备控制器
- 控制器控制表：每个控制器都配有一张COCT，它反应设备控制器的使用状态以及和通道的连接情况等
  	（控制器标识符、控制器状态、指向通道表的指针设备队列的队首指针、控制器队列的队尾指针）
- 通道控制表：每个通道配有一张CHCT
  	（通道标识符、通道状态、与通道连接的控制器表首址、通道队列的队首指针、通道队列的队尾指针）
- 系统设备表：整个系统只有一张SDT，它记录已连接到系统中的所有物理设备的情况，每个物理设备占一个表目

**3、静态分配与动态分配**

- 静态分配主要用于对独占设备的分配，它在用户作业开始执行前，有系统一次性分配该作业所要求的全部设备、控制器（和通道）。一旦分配后，这些设备、控制器（和通道）就一直为高作业所占用，知道该作业被撤销。静态分配方式不会出现死锁，但设备的使用效率较低。因此，静态分配方式并不符合分配的总原则。
- 动态分配是在进程执行过程中根据执行需要进行。当进程需要设备时，通过系统调用命令向系统提出设备请求，由系统按照事先规定的策略给进程分配所需要的设备、IO控制器，一旦用完之后，便立即释放。动态分配方式有利于提高设备的利用率，但如果分配算法使用不当，则有可能造成进程死锁

**4、设备分配算法**

常用的动态设备分配算法有先请求先分配、优先级高者优先等

对于独占设备，即可以采用动态分配方式也可以静态分配方式，往往采用静态分配方式，即在作业执行前，将作业所要用到的这一类设备分配给它
共享设备可被多个进程所共享，一般采用动态分配方式，但在每个IO传输的单位时间内只被一个进程所占有，通常采用先请求先分配和优先级高者先分的分配算法

**5、设备分配的安全性**

防止设备分配中发生进程死锁。

- 安全分配方式。每当进程发出IO请求后便进入阻塞状态，直到其IO操作完成时才被唤醒。这样，一旦进程已经获得某种设备后便阻塞，不嫩再请求任何资源，而且在它阻塞时也不保持任何资源。有点事设备分配安全；缺点是CPU和IO设备是串行工作的
- 不安全分配方式。进程在发出IO请求后继续运行，需要时发出第二个、第三个IO请求等。仅当进程所请求的设备已被另一进程占用时，才进入阻塞状态。有点事一个进程可以同时操作几个设备，从而市金城推进迅速；缺点是这种设备分配有可能产生死锁。为了提高设备分配的灵活性和设备的利用率、方便实现IO重定向，因此引入了设备独立性

**6、设备独立性**

应用程序独立于具体使用的物理设备

实现方式：在应用程序中使用逻辑设备名来请求使用某类设备，在系统中设置一张逻辑设备表（LUT），用于将逻辑设备名映射为物理设备名。LUT表项包括逻辑设备名、物理设备名和设备驱动程序入口地址；当进程用逻辑设备名来请求分配设备时，系统为他分配相应的物理设备，并在LUT中建立一个表项，以后进程再利用逻辑设备名请求IO操作时，系统通过查找LUT来寻找相应的物理设备和驱动程序。

建立逻辑设备表的两种方式：
	--- 在整个系统中只设置一张LUT表。所有进程的设备分配情况都记录在这张表中，故不允许有相同的逻辑设备名，主要适用于单用户系统中
	--- 为每个用户设置一张LUT。当用户登录时，系统便为用户建立一个进程，同时也位置建立一张LUT，并肩改变放入进程的PCB中

## 5.5 缓冲区管理

缓冲区：一个存储区域，可以由专门的硬件寄存器组成，也可利用内存作为缓冲区

在设备管理子系统中，引入缓冲区的目的有：
　　--- 缓和CPU与IO 设备间速度不匹配的矛盾。
　　--- 减少对CPU的中断频率，放宽对CPU 中断响应时间的限制。
　　--- 解决基本数据单元大小不匹配的问题。
　　--- 提高CPU和IO设备之间的并行性

**缓冲技术分类：**

### 1、单缓冲

在设备和处理器之间设置一个缓冲区。设备和处理器交换数据时，先把被交换数据写入缓冲区，然后把需要数据的设备或处理器从缓冲区取走数据

在块设备输入时，假定从磁盘把一块数据输入到缓冲区的时间为T，操作系统将该缓冲区中的数据局传送到用户区的时间为M，而CPU对这一块数据处理的时间为C。由于T和C是可以并行的，所以可把系统对每一块数据的处理时间表示为Max（C,T）+M

### 3、双缓冲

双缓冲区机制又称缓冲对换。IO设备输入数据时先输入到缓冲区1，直到缓冲区1满后才输入到缓冲区2，此时操作系统可以从缓冲区1中取出数据放入用户进程，并由CPU计算。双缓冲的使用提高了处理器和输入设备的并行操作的程度

系统处理一块数据的时间可以粗略地认为是Max（C,T）。如果CT，则可使CPU不必等待设备输入。对于字符设备，若采用行输入方式，则采用双缓冲可使用户再输入完第一行之后

### 4、循环缓冲

包含多个大小相等的缓冲区，每个缓冲区中有一个缓冲区，最后一个缓冲区指针指向第一个缓冲区，多个缓冲区构成一个环形。用于输入输出时，还需要有两个指针in和out。对输入而言，首先要从设备接收数据到缓冲区中，in指针指向可以输入数据的第一个空缓冲区；当运行进程需要数据时，从循环缓冲去中去一个装满数据的缓冲区，并从此缓冲区中提取数据，out指针指向可以提取数据的第一个满缓冲区。输出正好相反

### 5、缓冲池

由多个系统共用的缓冲区组成

缓冲区按其使用状况可以形成三个队列：空缓冲队列、装满输入数据的缓冲队列（输入队列）和装满输出数据的缓冲队列（输出队列）
还应具有四种缓冲区：用于收容输入数据的工作缓冲区、用于提取输入数据的工作缓冲区、用于收容输出数据的工作缓冲区、用于提取输出数据的工作缓冲区

---

---

# 随笔

线程：更小的一个概念，可以理解成一连串执行的指令，不拥有资源，共享进程的资源

进程：进行中的实例程序，拥有资源

# 参考书籍

[Operating Systems: Three Easy Pieces](https://github.com/remzi-arpacidusseau/ostep-translations)